# üçΩÔ∏è Sistema de Reservaci√≥n de Restaurantes

El sistema de reservaci√≥n de restaurantes es una plataforma digital basada en una arquitectura de microservicios que permite gestionar de manera eficiente y segura las operaciones relacionadas con la administraci√≥n de restaurantes, reservas, men√∫s, √≥rdenes y usuarios. Mediante el uso de tecnolog√≠as modernas, como bases de datos relacionales y NoSQL, motores de b√∫squeda, cacheo y balanceo de carga, el sistema facilita la creaci√≥n, consulta y modificaci√≥n de datos en tiempo real, ofreciendo una experiencia √°gil y escalable tanto para los administradores como para los clientes. Adem√°s, incorpora mecanismos de autenticaci√≥n, b√∫squeda avanzada y automatizaci√≥n de procesos para garantizar alta disponibilidad, rendimiento y facilidad de mantenimiento.

***Autoras***
* Mariann Mar√≠n Barquero
* Nicole Parra Valverde
* Stephanie Sandoval Camacho

## Requisitos

- Docker y Docker Compose

## ‚öôÔ∏è Configuraciones

### Variables de Entorno
Cree un archivo `.env` en la ra√≠z del proyecto con las variables de entorno necesarias. En este caso, en la ra√≠z se cre√≥ un archivo llamado `.envTemplate` con los nombres de las variables de entorno que se deben reemplazar.

### Configuraci√≥n del Realm en Keycloak
El sistema utiliza Keycloak como gestor de autenticaci√≥n y autorizaci√≥n. Para configurar el Realm, se deben seguir los siguientes pasos:

1. En el docker-compose.yml, en el servicio `keycloak`, se encontrar√°n dos l√≠neas comentadas. Descom√©ntelas y, en su lugar, comente las l√≠neas anteriores a estas para que obtenga la siguiente configuraci√≥n:

``` yml
keycloak:
  image: quay.io/keycloak/keycloak:24.0.1
  #command: start-dev
  command: start-dev --import-realm
  environment:
    KC_DB: postgres
    KC_DB_URL: jdbc:postgresql://keycloak-db:5432/keycloak
    KC_DB_USERNAME: keycloak
    KC_DB_PASSWORD: keycloak
    KEYCLOAK_ADMIN: admin
    KEYCLOAK_ADMIN_PASSWORD: admin
  ports:
    - "8080:8080"
  volumes:
    #- keycloak-data:/opt/keycloak/data
    - ./keycloak-realm:/opt/keycloak/data/import
  depends_on:
    keycloak-db:
      condition: service_healthy
  networks:
    - backend-network
```
2. Ejecute el siguiente comando:
``` bash
docker-compose up keycloak
```
3. Deje que el sistema termine de inicializarse y luego acceda a la URL `http://localhost:8080` en su navegador. Inicie sesi√≥n con el usuario `admin` y la contrase√±a `admin`. Luego, haga clic en el dropdown con el Realm actual en la esquina superior izquierda y verifica que existan dos realms:
  - `Keycloak master` (el que se crea autom√°ticamente).
  - `reserva-restaurantes` (el que se importa desde el archivo `keycloak-realm\reserva-restaurantes-realm.json`)
4. Cuando esto est√© listo, puede bajar el contenedor con el comando
``` bash
docker-compose down
```

## üöÄ Inicializaci√≥n del Sistema
Una vez que el sistema est√© configurado, puede inicializarlo con el comando
``` bash
docker-compose up --build -d
```
Esto levantar√° todos los servicios: PostgreSQL, MongoDB, Redis, ElasticSearch, Keycloak junto con su base de datos y la API REST.

### Consideraciones Importantes
- Antes de ejecutar el comando anterior, se debe haber devuelto la configuraci√≥n de Keycloak a su estado original, es decir, que se debieron descomentar las l√≠neas comentadas en el archivo `docker-compose.yml` y se tuvieron que comentar las l√≠neas que se descomentaron anteriormente.
- La variable de entorno `REINDEX_ON_START` se debe establecer en `false` ya que aun no existen productos en ninguna base de datos para reindexar. Una vez que existan productos, se puede establecer en `true` para reindexarlos.
- La variable de entorno `DB_TYPE` se debe establecer en `postgres` o `mongo` seg√∫n la base de datos que se desee utilizar.

## üçÄ Inicializaci√≥n del Cl√∫ster Shardeado de MongoDB
Una vez que el sistema est√° arriba, si la base de datos seleccionada es MongoDB, se debe inicializar el cl√∫ster de MongoDB. Para esto, se deben seguir los siguientes pasos:
1. Inicializar el Config Server Replica Set
``` bash
docker exec -it mongo-config1 mongosh
```

``` js
rs.initiate({
  _id: "configReplSet",
  configsvr: true,
  members: [
    { _id: 0, host: "mongo-config1:27017" },
    { _id: 1, host: "mongo-config2:27017" },
    { _id: 2, host: "mongo-config3:27017" }
  ]
});
```

2. Inicializar el Shard Replica Set
``` bash
docker exec -it mongors1n1 mongosh
```

``` js
rs.initiate({
  _id: "mongors1",
  members: [
    { _id: 0, host: "mongors1n1:27017" },
    { _id: 1, host: "mongors1n2:27017" },
    { _id: 2, host: "mongors1n3:27017" }
  ]
});
```

- Si se quiere revisar el estado de los replicaset, se puede hacer con el comando `rs.status()` en el shell de MongoDB.

3. Configuraci√≥n del Sharding
``` bash
docker exec -it mongos mongosh
```

``` js
sh.addShard("mongors1/mongors1n1:27017,mongors1n2:27017,mongors1n3:27017")
sh.enableSharding("Restaurante")
```

## ü§ñ CI/CD con GitHub Actions

Este proyecto incluye una integraci√≥n continua b√°sica usando **GitHub Actions** para asegurar la calidad y facilitar el despliegue.

### Estructura del Workflow

El flujo de trabajo principal se encuentra en:

`.github/workflows/ci.yml`

### ¬øQu√© hace el Workflow?

1. Ejecute los tests definidos con Jest (`npm test`)
2. Construya la imagen Docker del backend
3. La sube autom√°ticamente a Docker Hub si los tests pasan

### Configuraci√≥n Requerida en GitHub

Debe agregar sus credenciales de Docker Hub como *secrets* en su repositorio de GitHub:

- Vaya a **Settings ‚Üí Secrets and variables ‚Üí Actions** y agregue:

| Variable          | Descripci√≥n                         |
|-------------------|-------------------------------------|
| `DOCKER_USERNAME` | Su usuario de Docker Hub            |
| `DOCKER_PASSWORD` | Su contrase√±a o token de Docker Hub |

### Convenci√≥n para los tags

La imagen se sube como:

`docker.io/<tu_usuario>/restaurantes-e2:latest`

Se puede modificar el nombre y tag directamente en el archivo `ci.yml`.

### Escalabilidad

Se levantan dos instancias del backend (`api1`, `api2`), accesibles a trav√©s de NGINX en:

* http://localhost/api/

Se puede probar la distribuci√≥n de carga con:

``` bash
while true; do curl http://localhost/api/ping; sleep 1; done
```

Ver√° que las respuestas alternan entre los contenedores gracias al  round-robin configurado en NGINX.

#### Balanceador de carga (NGINX)

El archivo `nginx.conf` contiene la siguiente configuraci√≥n

``` conf
upstream api_backend {
  server api1:5000;
  server api2:5000;
}

server {
  listen 80;

  location /api/ {
    proxy_pass http://api_backend;
  }

  location /search/ {
    proxy_pass http://search_backend;
  }
}
```

* La ruta `/api/` balancea entre instancias del backend.
* La ruta `/search/` redirige a un servicio de b√∫squeda.

## ‚ö° Uso de la API
La API se utiliza para realizar operaciones con los principales objetos que maneja el sistema: usuarios, restaurantes, men√∫s, √≥rdenes, reservaciones y productos. A continuaci√≥n, se incluyen los m√©todos disponibles para cada objeto:

### üî∏ Autenticaci√≥n
| M√©todo | Ruta               | Funci√≥n                                                                 |
|--------|--------------------|-------------------------------------------------------------------------|
| POST   | `/auth/register`   | Registra un nuevo usuario en Keycloak y en la base de datos en uso      |
| POST   | `/auth/login`      | Inicia sesi√≥n para un usuario (devuelve token JWT de Keycloak)          |
| POST   | `/clone`           | Clona un usuario de PostgreSQL a MongoDB                                |

### üî∏ Usuarios
| M√©todo | Ruta           | Funci√≥n                                                                 |
|--------|----------------|-------------------------------------------------------------------------|
| GET    | `/users/me`    | Devuelve informaci√≥n del usuario con sesi√≥n activa                      |
| PUT    | `/users/:id`   | Actualiza informaci√≥n en Keycloak y base de datos                       |
| DELETE | `/users/:id`   | Elimina cuenta en Keycloak y base de datos                              |

### üî∏ Restaurantes
| M√©todo | Ruta              | Funci√≥n                                                                 |
|--------|-------------------|-------------------------------------------------------------------------|
| POST   | `/restaurants`    | Agrega un nuevo restaurante                                             |
| GET    | `/restaurants`    | Lista todos los restaurantes                                            |

### üî∏ Men√∫s
| M√©todo | Ruta            | Funci√≥n                                                                 |
|--------|-----------------|-------------------------------------------------------------------------|
| POST   | `/menus`        | Agrega un nuevo men√∫                                                    |
| GET    | `/menus/:id`    | Obtiene detalles de un men√∫ espec√≠fico                                  |
| PUT    | `/menus/:id`    | Actualiza un men√∫ existente                                             |
| DELETE | `/menus/:id`    | Elimina un men√∫                                                         |

### üî∏ Reservaciones
| M√©todo | Ruta                  | Funci√≥n                                                                 |
|--------|-----------------------|-------------------------------------------------------------------------|
| POST   | `/reservations`       | Crea una nueva reservaci√≥n                                              |
| GET    | `/reservations/:id`   | Obtiene detalles de una reservaci√≥n                                     |
| DELETE | `/reservations/:id`   | Cancela una reservaci√≥n                                                 |

### üî∏ √ìrdenes
| M√©todo | Ruta             | Funci√≥n                                                                 |
|--------|------------------|-------------------------------------------------------------------------|
| POST   | `/orders`        | Crea una nueva orden                                                    |
| GET    | `/orders/:id`    | Obtiene detalles de una orden espec√≠fica                                |

### üî∏ Productos
| M√©todo | Ruta              | Funci√≥n                                                                 |
|--------|-------------------|-------------------------------------------------------------------------|
| POST   | `/products`       | Agrega un nuevo producto                                                |
| GET    | `/products`       | Lista todos los productos                                               |
| DELETE | `/products/:id`   | Elimina un producto                                                     |

## üîç Uso del Servidor de B√∫squedas
El sistema de b√∫squedas se utiliza para realizar consultas complejas de los productos almacenados en la base de datos. Para esto, se aprovecha las funcionalidades de ElasticSearch para realizar consultas de texto, por categor√≠a o incluso una combinaci√≥n de ambas. A continuaci√≥n, se incluyen los m√©todos disponibles para el servidor de b√∫squedas:

### üîπ Productos (B√∫squeda con ElasticSearch)

| M√©todo | Ruta                          | Funci√≥n                                                                 |
|--------|-------------------------------|-------------------------------------------------------------------------|
| GET    | `/products`                   | B√∫squeda en ElasticSearch por:<br>- T√©rmino (`?q=texto`)<br>- Categor√≠a (`?category=valor`)<br>- Ambos criterios combinados |
| GET    | `/products/category/:category`| B√∫squeda filtrada exclusivamente por categor√≠a                          |
| POST   | `/reindex`                    | Ejecuta una reindexaci√≥n manual completa de productos en ElasticSearch  |

## üì¶ Ejemplos de Uso

[Ejemplos de Uso](EXAMPLES.md)

## üé• Video
Se incluye un video que muestra la funcionalidad del sistema en acci√≥n. Tanto en su primera etapa como en la segunda:

[Video Demostrativo](https://drive.google.com/drive/folders/1D_IdkLbZQNpx5ySEPajmJff1t3Pw8g1x) 

## üêù Paso a Paso para Inicializar el Data Warehouse (Hive)

1. Levanta todos los servicios. Desde la ra√≠z del proyecto

``` bash
docker-compose up --build
``` 

2. Ingresa al contenedor del Hive Server

``` bash
docker exec -it hive-server bash
``` 

3. Inicializa el esquema del metastore

Dentro del contenedor de Hive Server, ejecuta:

``` bash
schematool -dbType postgres -initSchema
```

Esto inicializa el esquema del metascore, crea las tablas internas necesarias para que Hive funcione.

4. Posterior a eso se ejecuta el siguiente comando (desde la ra√≠z del proyecto):

``` bash
docker cp db/star-schema.hql hive-server:/tmp/star-schema.hql
```
``` bash
docker cp db/cubosOLAP.hql hive-server:/tmp/cubosOLAP.hql
``` 

Este comando copia el archivo [Script de creaci√≥n del datawarehouse](db/star-schema.hql) desde la m√°quina local al contenedor del hive-server y tambi√©n los cubos olap

5. Inicia el servicio HiveServer2

Dentro del contenedor de Hive Server:

``` bash
hive --service hiveserver2 &
```
Esto habilita el puerto JDBC (10000) necesario para ejecutar comandos con Beeline.

6. Verifica que HiveServer2 est√° corriendo

Dentro del contenedor, ejecuta:

``` bash
netstat -tulnp
```

Deber√≠a devolverle algo as√≠:

```
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 127.0.0.11:39917        0.0.0.0:*               LISTEN      -
tcp        0      0 0.0.0.0:10002           0.0.0.0:*               LISTEN      226/java
tcp        0      0 0.0.0.0:10000           0.0.0.0:*               LISTEN      226/java
udp        0      0 127.0.0.11:33011        0.0.0.0:*                           -
```

Note que el `0 0.0.0.0:10000` est√° en estado `LISTEN`

7. Ejecuta el script para crear las tablas del data warehouse

Dentro del contenedor de Hive Server:

El siguiente es para las tablas del dw.
``` bash
beeline -u jdbc:hive2://localhost:10000 -n hive -f /tmp/star-schema.hql
```
Y este otro es para las vistas
``` bash
beeline -u jdbc:hive2://localhost:10000 -n hive -f /tmp/cubosOLAP.hql
``` 

8.  Verifica las tablas creadas

Abre el cliente Beeline dentro del contenedor:

``` bash
beeline -u jdbc:hive2://localhost:10000 -n hive
```

Dentro de Beeline se puede ejecutar:

``` bash
SHOW TABLES;
```
Muestra las tablas existentes

``` bash
DESCRIBE fact_orders;
```
Este muestra la estructura de una tabla, cambie `fact_orders` por la tabla que necesite observar

## üóÑÔ∏è Rellenar la Base de Datos

1. Instalar dependencias
Asegurarse de tener instalados los paquetes necesarios (ya incluidos en package.json), sino ejecutar:

``` bash
npm install
```
2. Reiniciar el volumen de Postgres
En caso de tener la estructura de la base de datos de postgres antigua, eliminar el volumen para empezar desde cero:

``` bash
docker volume rm restaurantes-e2_db-data
```
3. Cargar datos de ejemplo
Una vez levantado los contenedores esperar a que el contenedor de Postgres est√© listo y ejecutar:

``` bash
node db/fill_postgres.js
```

## üí® Configuraci√≥n de airflow y ejecuci√≥n del entorno ETL

(Airflow suele necesitar de 4GB, en caso de ser necesario configurar la RAM asignada a Docker-Desktop)

1. Levantar los servicios 

``` bash
docker-compose up
```
Esto puede ser muy pesado as√≠ que se puede levantar solo los necesarios de esta forma: 

``` bash
docker-compose up db airflow-db airflow-webserver airflow-scheduler airflow-init spark-master spark-worker
```

2. Ejecutar el DAG de extracci√≥n

  * Acceder a `http://localhost:8081` con las credenciales (en este caso user `admin`, password `admin`)
  * Activar el DAG (toggle ON)
  * Hacer clic en el bot√≥n de `play` (Trigger DAG) para ejecutarlo manualmente
  * Se puede monitorear el progreso en la pesta√±a `Graph View` o `Tree View`
  * Una vez hayan terminado todas las tareas verificar la creaci√≥n de los archivos en 
      [Data](airflow/dags/data/)
  * Por √∫ltimo para la carga al datawarehouse hacer lo siguiente

a. Para ingresar al contenedor del hive

``` bash
docker exec -it hive-server bash
``` 
b. Abre el cliente Beeline dentro del contenedor:

``` bash
beeline -u jdbc:hive2://localhost:10000 -n hive
```
c. Reparar las particiones en Hive
Esto es necesario para que Hive reconozca las nuevas particiones creadas por Spark:

``` sql
MSCK REPAIR TABLE fact_orders;
MSCK REPAIR TABLE fact_reservations;
```

## üìä Dashboards con Superset

El sistema incluye **Apache Superset** para la visualizaci√≥n y an√°lisis de datos a trav√©s de dashboards interactivos.

- Se puede acceder a Superset desde el navegador en:  
  [http://localhost:8082](http://localhost:8082)

- Se ingresa con las credenciales configuradas (son `admin` / `admin`, esas se crean apenas levanta el contenedor).

- **Importante:**  
  El archivo `superset.db` contiene la configuraci√≥n interna y los dashboards creados en Superset.  
  **Si se altera ese archivo sin haber hecho uso de Superset, cabe la posibilidad de que el contenedor no levante**

  En caso de que eso sucediera, el commit **feat: superset dashboards ready** tiene la versi√≥n m√°s actualizada del superset.db. Entonces se puede reemplazar el archivo actual por ese y volver a levantar contenedores.